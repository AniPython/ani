{% extends 'crawler/includes/crawler_base.html' %}

{% block 说明 %}
    反爬: 无
{% endblock %}


{% block 爬取内容 %}
    <nav aria-label="Page navigation">
        <ul class="pagination">
            {% if page_obj.has_previous %}
                <li class="page-item">
                    <a class="page-link" href="?page={{ page_obj.previous_page_number }}"
                       aria-label="Previous">
                        <span aria-hidden="true">&laquo;</span>
                    </a>
                </li>
            {% else %}
                <li class="page-item disabled">
                    <a class="page-link"
                       href="" aria-label="Previous">
                        <span aria-hidden="true">&laquo;</span>
                    </a>
                </li>
            {% endif %}

            {% for page in paginator.page_range %}
                <li id="page{{ page }}" class="page-item">
                    <a class="page-link"
                       href="?page={{ page }}">{{ page }}</a>
                </li>
            {% endfor %}

            {% if page_obj.has_next %}
                <li class="page-item">
                    <a class="page-link" href="?page={{ page_obj.next_page_number }}"
                       aria-label="Next">
                        <span aria-hidden="true">&raquo;</span>
                    </a>
                </li>
            {% else %}
                <li class="page-item disabled">
                    <a class="page-link" href=""
                       aria-label="Next">
                        <span aria-hidden="true">&raquo;</span>
                    </a>
                </li>
            {% endif %}
        </ul>
    </nav>
    <div class="title">
        {% for item in page_obj %}
            <p>
                <a class="text-decoration-none" href="{% url 'crawler:crawler4_detail' item.id %}">{{ item.title }}</a>
            </p>
        {% endfor %}
    </div>
{% endblock %}


{% block 方案1标题 %}
    方案1: <code>requests</code>, <code>xpath</code>, <code>pandas</code>
{% endblock %}


{% block 方案1详情 %}
    <h5 class="card-title">获取全部结果统一输出</h5>
    <p class="card-text">
        1. 从外层的全部页面, 获取全部的 title url <br>
        2. 遍历全部的 title url, 获取详情页内容 <br>
        3. 保存到本地 <br>
    </p>

    <div>
        <div class="highlight rounded-3">
            <pre class="prettyprint lang-python border-0">{{ code_crawler4_1 }}</pre>
        </div>
    </div>
{% endblock %}


{% block 方案2标题 %}
    方案2: <code>scrapy</code>爬虫框架
{% endblock %}


{% block 方案2详情 %}

    <!-- 代码 -->
    <h5>scrapy</h5>
    <ul>
        <li>scrapy 是最流行的爬虫框架</li>
        <li>爬虫工程师必知必会</li>
        <li>它可以帮忙我们更好更快地完成任务</li>
    </ul>
    <h5>安装和基本使用</h5>
    <div>
        <div class="highlight rounded-3">
                            <pre class="language-bash">$ pip3 install scrapy
$ scrapy startproject ani Ani
$ cd Ani
$ scrapy genspider -t crawl crawler4 127.0.0.1:8000
// 修改代码 Ani.ani.spiders.crawler4.py
$ scrapy crawl crawler4 -o result.csv</pre>
        </div>
    </div>
    <h5>完整代码</h5>
    <div>
        <div class="highlight rounded-3">
            <pre class="prettyprint lang-python border-0">{{ code_crawler4_2 }}</pre>
        </div>
    </div>


{% endblock %}


{% block 方案3标题 %}
    xxx
{% endblock %}


{% block 方案3详情 %}
    xxx
{% endblock %}


{# 不显示方案2 #}
{#{% block 方案2 %}{% endblock %}#}

{# 不显示方案3 #}
{% block 方案3 %}{% endblock %}
